"""
Implement the Question Agent using LangChain.

LangChain ã‚’ä½¿ã£ã¦ Question Agent ã‚’å®Ÿè£…ã—ã¾ã™ã€‚
"""

from typing import Dict, List, Any, Optional, Callable, Awaitable
import os
import json
import asyncio
from unittest.mock import MagicMock, AsyncMock

# ä¿®å¤å¯¼å…¥è·¯å¾„
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain.agents.agent import AgentExecutor
from langchain.agents.react.base import create_react_agent
from langchain.chains import LLMChain
from langchain_core.tools import Tool
from langchain_core.language_models import BaseLLM
from langchain_core.pydantic_v1 import BaseModel, Field

from app.infra.uow import UnitOfWork
from app.llm import LLMModel
from app.services.tools.function.search import search_resource
from app.services.common.memory import MemoryService
from app.services.common.mistake import MistakeService
from app.services.common.vocab import VocabService
from app.services.common.story import StoryService


class SearchInput(BaseModel):
    """
    Search input for the search tool.
    
    æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã®ãŸã‚ã®å…¥åŠ›ã§ã™ã€‚
    """
    resource: str = Field(description="Resource type to search for")
    field: str = Field(description="Field name to search within")
    query: str = Field(description="Query string to search with")
    method: str = Field(description="Search method (regex or vector)", default="regex")
    limit: int = Field(description="Max number of results to return", default=20)


def get_search_tool(uow: UnitOfWork) -> Tool:
    """
    Create a search tool for the agent.
    
    Agent ã®ãŸã‚ã®æ¤œç´¢ãƒ„ãƒ¼ãƒ«ã‚’ä½œæˆã—ã¾ã™ã€‚
    """
    async def search_func(input_str: str) -> str:
        try:
            # Parse the input string as JSON
            input_data = SearchInput.parse_raw(input_str)
            # Call the search_resource function
            results = await search_resource(
                uow=uow,
                resource=input_data.resource,
                field=input_data.field,
                query=input_data.query,
                method=input_data.method,
                limit=input_data.limit
            )
            return str(results)
        except Exception as e:
            return f"Error searching resource: {str(e)}"
    
    return Tool(
        name="search_resource",
        description="""
Search for resources in the database.
Resource types: vocab, grammar, mistakes, stories, memories
Fields depend on resource type:
- vocab: name, usage
- grammar: name, usage
- memory: content
- story: content, summary, category
- mistake: question, answer, correct_answer, error_reason
Method can be 'regex' or 'vector'
        """,
        func=search_func,
        args_schema=SearchInput
    )


class LangChainQuestionAgent:
    """
    Question Agent implementation using LangChain.
    
    LangChain ã‚’ä½¿ã£ãŸ Question Agent ã®å®Ÿè£…ã§ã™ã€‚
    """
    
    def __init__(self, uow: UnitOfWork, model_type: LLMModel = LLMModel.STANDARD):
        """
        Initialize the agent with the unit of work and model type.
        
        Agent ã‚’ Unit of Work ã¨ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã§åˆæœŸåŒ–ã—ã¾ã™ã€‚
        """
        self.uow = uow
        self.model_type = model_type
        
        # ä½¿ç”¨æ¨¡å‹é…ç½®
        model_name = model_type.value["name"]
        self.llm = ChatOpenAI(
            temperature=0.7,
            model_name=model_name
        )
        
        # è®¾ç½®å·¥å…·
        self.tools = [get_search_tool(uow)]
        
        # å­˜å‚¨OPARå¾ªç¯çš„çŠ¶æ€å’Œç»“æœ
        self.observation_results = []
        self.plan_results = {}
        self.action_results = []
        self.reflection_result = None
        
        # è°ƒè¯•æ¨¡å¼
        self.debug = False
    
    async def _is_new_user(self) -> bool:
        """
        Check if the current user is a new user.
        
        ç¾åœ¨ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ–°ã—ã„ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã©ã†ã‹ã‚’ç¢ºèªã—ã¾ã™ã€‚
        """
        # Get user memories and check if they exist
        memories = await MemoryService(self.uow).get_user_memories_list(limit=1)
        return len(memories) == 0
    
    async def _observe(self, user_input: str) -> None:
        """
        Observation stage: collect and analyze information about the user.
        
        è¦³å¯Ÿæ®µéš: ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«é–¢ã™ã‚‹æƒ…å ±ã‚’åé›†ã—ã€åˆ†æã—ã¾ã™ã€‚
        """
        # è·å–ç”¨æˆ·ç›¸å…³æ•°æ®
        memories = await MemoryService(self.uow).get_user_memories_list(limit=20)
        memory_categories = await MemoryService(self.uow).get_user_memory_categories_with_number()
        mistakes = await MistakeService(self.uow).get_user_mistakes(limit=5)
        
        # æ„å»ºè§‚å¯Ÿé˜¶æ®µæç¤ºè¯
        observe_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ä½ æ˜¯ä¸€ä¸ªè¯­è¨€å­¦ä¹ å¹³å°çš„æ™ºèƒ½è§‚å¯Ÿä»£ç†ï¼Œç”¨æˆ·æ­£åœ¨å­¦ä¹ ç›®æ ‡è¯­è¨€ã€‚
ä½ çš„ä»»åŠ¡æ˜¯åˆ†æå½“å‰è¯·æ±‚ä¸‹ï¼Œéœ€è¦æœç´¢å“ªäº›ä¿¡æ¯æ‰èƒ½å®Œæˆç”¨æˆ·çš„ç”»åƒï¼Œå¹¶è¿”å›éœ€è¦åœ¨æ•°æ®åº“æ£€ç´¢çš„å†…å®¹ã€‚

éœ€è¦è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š
1. ç”¨æˆ·å½“å‰çš„æ°´å¹³å’Œå­¦ä¹ ç›®æ ‡æ˜¯ä»€ä¹ˆ
2. ç”¨æˆ·å–œæ¬¢å“ªäº›ä¸œè¥¿ï¼Œæƒ³è¦å­¦ä¼šè¯­è¨€æœ€é‡è¦çš„æ˜¯å’Œç”Ÿæ´»ä¸çˆ±å¥½ç›¸å…³çš„å¥‘æœº
3. ç”¨æˆ·å¯èƒ½ä¼šåœ¨ä»€ä¹ˆåœ°æ–¹å‘ç”Ÿé”™è¯¯ï¼Œåº”è¯¥æ€ä¹ˆå»æ£€ç´¢è¿™äº›é”™è¯¯è®°å½•

ä½ å¯ä»¥ä½¿ç”¨search_resourceå·¥å…·æœç´¢ä»¥ä¸‹èµ„æºï¼š
- vocab (è¯æ±‡): å¯æœç´¢nameå’Œusageå­—æ®µ
- grammar (è¯­æ³•): å¯æœç´¢nameå’Œusageå­—æ®µ
- memory (è®°å¿†): å¯æœç´¢contentå­—æ®µ
- story (æ•…äº‹): å¯æœç´¢contentã€summaryå’Œcategoryå­—æ®µ
- mistake (é”™é¢˜): å¯æœç´¢questionã€answerã€correct_answerå’Œerror_reasonå­—æ®µ

è¯·ä¸»åŠ¨æœç´¢ç›¸å…³èµ„æºï¼Œä»¥è·å–æ›´å‡†ç¡®çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
            """),
            ("user", """
ä¸‹é¢é™„å¸¦äº†ä¸€äº›AIå¯¹ç”¨æˆ·çš„ç”»åƒï¼Œå…¨éƒ¨éƒ½æ˜¯ç”±AIä¸»åŠ¨è®°å½•çš„
å…³äºè¿™ä¸ªç”¨æˆ·å½“å‰è¯­è¨€çš„æœ€é‡è¦çš„æœ€è¿‘çš„è®°å¿†: {memories}
ç”¨æˆ·è®°å¿†çš„categoryå’Œæ•°é‡ï¼š{memory_categories}
å…³äºè¿™ä¸ªç”¨æˆ·å½“å‰è¯­è¨€çš„æœ€è¿‘çš„é”™é¢˜ï¼š{mistakes}

ç”¨æˆ·è¯·æ±‚ï¼š{user_input}
åˆ†æè¿™ä¸ªè¯·æ±‚å¹¶ä¸»åŠ¨æœç´¢ç›¸å…³å­¦ä¹ èµ„æºã€‚
            """)
        ])
        
        # åˆ›å»ºReActä»£ç†
        agent = create_react_agent(self.llm, self.tools, observe_prompt)
        agent_executor = AgentExecutor(
            agent=agent,
            tools=self.tools,
            verbose=self.debug,
            handle_parsing_errors=True
        )
        
        # è¿è¡Œä»£ç†
        response = await agent_executor.ainvoke({
            "memories": memories,
            "memory_categories": memory_categories,
            "mistakes": mistakes,
            "user_input": user_input,
        })
        
        # å­˜å‚¨è§‚å¯Ÿç»“æœ
        self.observation_results = response["output"]
    
    async def _plan(self) -> None:
        """
        Planning stage: plan the questions based on observations.
        
        è¨ˆç”»æ®µéš: è¦³å¯Ÿã«åŸºã¥ã„ã¦å•é¡Œã‚’è¨ˆç”»ã—ã¾ã™ã€‚
        """
        # æ„å»ºè®¡åˆ’é˜¶æ®µæç¤ºè¯
        plan_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ä½ æ˜¯è¯­è¨€å­¦ä¹ å¹³å°çš„é—®é¢˜è§„åˆ’ä»£ç†ã€‚
æ ¹æ®è§‚å¯Ÿç»“æœï¼Œä¸ºç”¨æˆ·è§„åˆ’ä¸€ç»„é—®é¢˜ã€‚

éœ€è¦ç¡®å®šï¼š
1. ç”Ÿæˆå¤šå°‘é—®é¢˜ï¼ˆæ¨è5-10é¢˜ï¼‰
2. åŒ…å«å“ªäº›ç±»å‹çš„é—®é¢˜ï¼ˆé€‰æ‹©é¢˜ã€å¡«ç©ºé¢˜ã€è‡ªç”±å›ç­”ç­‰ï¼‰
3. åŸºäºç”¨æˆ·å†å²å’Œå­¦ä¹ éœ€æ±‚çš„é‡ç‚¹é¢†åŸŸ
4. é€‚åˆç”¨æˆ·çš„éš¾åº¦çº§åˆ«

å¯ç”¨çš„é—®é¢˜ç±»å‹ï¼š
- choiceï¼šé€‰æ‹©é¢˜
- match_audioï¼šéŸ³é¢‘å’Œæ–‡æœ¬åŒ¹é…
- match_nativeï¼šæ¯è¯­å’Œç›®æ ‡è¯­è¨€åŒ¹é…
- clozeï¼šå¡«ç©ºé¢˜
- orderï¼šå¥å­æ’åº
- freeï¼šè‡ªç”±å›ç­”
- free_limitï¼šå¸¦æœ‰æŒ‡å®šè¯æ±‡/è¯­æ³•çš„è‡ªç”±å›ç­”
- roleplayï¼šè§’è‰²æ‰®æ¼”ä»¥è¾¾æˆç›®æ ‡

è¯·è¿”å›JSONæ ¼å¼çš„è®¡åˆ’ï¼ŒåŒ…å«question_countã€question_typesã€difficultyå’Œfocuså­—æ®µã€‚
            """),
            ("user", "è§‚å¯Ÿç»“æœï¼š\n{observations}\n\nè¯·åˆ›å»ºé—®é¢˜ç”Ÿæˆè®¡åˆ’ã€‚")
        ])
        
        # åˆ›å»ºè®¡åˆ’é“¾
        plan_chain = LLMChain(llm=self.llm, prompt=plan_prompt)
        
        # è¿è¡Œè®¡åˆ’é“¾
        response = await plan_chain.ainvoke({"observations": self.observation_results})
        
        # è§£æè®¡åˆ’ç»“æœ
        try:
            self.plan_results = json.loads(response["text"])
        except:
            # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤è®¡åˆ’
            self.plan_results = {
                "question_count": 5,
                "question_types": ["choice", "cloze", "free"],
                "difficulty": "beginner",
                "focus": "general_assessment"
            }
    
    async def _act(self) -> None:
        """
        Action stage: generate questions based on the plan.
        
        è¡Œå‹•æ®µéš: è¨ˆç”»ã«åŸºã¥ã„ã¦å•é¡Œã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        """
        # é‡ç½®è¡ŒåŠ¨ç»“æœ
        self.action_results = []
        
        # è·å–è®¡åˆ’å‚æ•°
        question_count = self.plan_results.get("question_count", 5)
        question_types = self.plan_results.get("question_types", ["choice"])
        difficulty = self.plan_results.get("difficulty", "beginner")
        focus = self.plan_results.get("focus", "general")
        
        # æ„å»ºè¡ŒåŠ¨é˜¶æ®µæç¤ºè¯
        act_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ä½ æ˜¯ä¸€ä¸ªè¯­è¨€å­¦ä¹ å¹³å°çš„é—®é¢˜ç”Ÿæˆä»£ç†ã€‚
ç”Ÿæˆä¸€ä¸ªå…·æœ‰ä»¥ä¸‹å‚æ•°çš„é—®é¢˜ï¼š
- éš¾åº¦ï¼š{difficulty}
- é‡ç‚¹é¢†åŸŸï¼š{focus}
- é—®é¢˜ç±»å‹ï¼š{question_type}

åŒ…æ‹¬é—®é¢˜æ‰€éœ€çš„æ‰€æœ‰å¿…è¦ä¿¡æ¯ï¼Œä¾‹å¦‚ï¼š
- é—®é¢˜æ–‡æœ¬
- ç­”æ¡ˆé€‰é¡¹ï¼ˆå¯¹äºé€‰æ‹©é¢˜ï¼‰
- æ­£ç¡®ç­”æ¡ˆ
- è§£é‡Šä¸ºä»€ä¹ˆç­”æ¡ˆæ˜¯æ­£ç¡®çš„

è¯·ä»¥JSONæ ¼å¼è¿”å›é—®é¢˜æ•°æ®ã€‚
            """),
            ("user", """
è¯·ç”Ÿæˆç¬¬{q_num}é¢˜ï¼ˆå…±{total}é¢˜ï¼‰ã€‚
ä½¿ç”¨ä»¥ä¸‹è§‚å¯Ÿç»“æœå’Œè®¡åˆ’ä½œä¸ºä¸Šä¸‹æ–‡ï¼š

è§‚å¯Ÿç»“æœï¼š
{observations}

è®¡åˆ’ï¼š
{plan}
            """)
        ])
        
        # åˆ›å»ºè¡ŒåŠ¨é“¾
        act_chain = LLMChain(llm=self.llm, prompt=act_prompt)
        
        # ç”Ÿæˆé—®é¢˜
        for i in range(question_count):
            # é€‰æ‹©é—®é¢˜ç±»å‹
            q_type = question_types[i % len(question_types)]
            
            # è¿è¡Œè¡ŒåŠ¨é“¾
            response = await act_chain.ainvoke({
                "difficulty": difficulty,
                "focus": focus,
                "question_type": q_type,
                "q_num": i + 1,
                "total": question_count,
                "observations": self.observation_results,
                "plan": self.plan_results
            })
            
            # è§£æå’Œå­˜å‚¨é—®é¢˜
            try:
                question_data = json.loads(response["text"])
                # å¦‚æœæ²¡æœ‰é—®é¢˜ç±»å‹åˆ™æ·»åŠ 
                if "question_type" not in question_data:
                    question_data["question_type"] = q_type
                self.action_results.append(question_data)
            except:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå­˜å‚¨åŸå§‹æ–‡æœ¬
                self.action_results.append({
                    "question_type": q_type,
                    "raw_data": response["text"]
                })
    
    async def _reflect(self) -> bool:
        """
        Reflection stage: evaluate the generated questions.
        
        åçœæ®µéš: ç”Ÿæˆã•ã‚ŒãŸå•é¡Œã‚’è©•ä¾¡ã—ã¾ã™ã€‚
        """
        # æ„å»ºåæ€é˜¶æ®µæç¤ºè¯
        reflect_prompt = ChatPromptTemplate.from_messages([
            ("system", """
ä½ æ˜¯ä¸€ä¸ªè¯­è¨€å­¦ä¹ å¹³å°çš„åæ€ä»£ç†ã€‚
è¯„ä¼°ç”Ÿæˆçš„é—®é¢˜çš„è´¨é‡å’Œé€‚åˆåº¦ã€‚

è€ƒè™‘ä»¥ä¸‹å‡ ç‚¹ï¼š
1. é—®é¢˜æ˜¯å¦ç¬¦åˆç”¨æˆ·çš„å­¦ä¹ éœ€æ±‚å’Œæ°´å¹³ï¼Ÿ
2. é—®é¢˜æ˜¯å¦å¤šæ ·åŒ–ä¸”æœ‰å¸å¼•åŠ›ï¼Ÿ
3. é—®é¢˜æ˜¯å¦å­˜åœ¨ä»»ä½•é—®é¢˜ï¼ˆæ­§ä¹‰ã€é”™è¯¯ç­‰ï¼‰ï¼Ÿ
4. æ€»ä½“è€Œè¨€ï¼Œè¿™äº›é—®é¢˜æ˜¯å¦é€‚åˆç”¨æˆ·ï¼Ÿ

æä¾›è¯¦ç»†è¯„ä¼°ï¼Œå¹¶ç¡®å®šè¿™äº›é—®é¢˜æ˜¯å¦å¯ä»¥å‘ˆç°ç»™ç”¨æˆ·ã€‚
å¦‚æœä¸è¡Œï¼Œè¯·æŒ‡æ˜åº”è¯¥é‡è¯•å“ªä¸ªé˜¶æ®µï¼š"observe"ã€"plan"æˆ–"act"ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›è¯„ä¼°ç»“æœï¼ŒåŒ…å«is_validï¼ˆå¸ƒå°”å€¼ï¼‰ã€reasonï¼ˆå­—ç¬¦ä¸²ï¼‰å’Œstage_to_retryï¼ˆå­—ç¬¦ä¸²ï¼Œå¯é€‰ï¼‰å­—æ®µã€‚
            """),
            ("user", """
åŸå§‹ç”¨æˆ·è¯·æ±‚ï¼š{user_input}

è§‚å¯Ÿç»“æœï¼š
{observations}

è®¡åˆ’ï¼š
{plan}

ç”Ÿæˆçš„é—®é¢˜ï¼š
{questions}

è¯·è¯„ä¼°è¿™äº›é—®é¢˜å¹¶ç¡®å®šå®ƒä»¬æ˜¯å¦åˆé€‚ã€‚
            """)
        ])
        
        # åˆ›å»ºåæ€é“¾
        reflect_chain = LLMChain(llm=self.llm, prompt=reflect_prompt)
        
        # è¿è¡Œåæ€é“¾
        response = await reflect_chain.ainvoke({
            "user_input": self.user_input,
            "observations": self.observation_results,
            "plan": self.plan_results,
            "questions": self.action_results
        })
        
        # è§£æåæ€ç»“æœ
        try:
            self.reflection_result = json.loads(response["text"])
        except:
            # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤ç»“æœ
            self.reflection_result = {
                "is_valid": True,
                "reason": "Generated questions seem appropriate."
            }
        
        return self.reflection_result.get("is_valid", True)
    
    async def run(self, user_input: str) -> Dict[str, Any]:
        """
        Run the complete OPAR cycle to generate questions.
        
        OPAR ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œã—ã¦å•é¡Œã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        """
        # å­˜å‚¨ç”¨æˆ·è¾“å…¥
        self.user_input = user_input
        
        # æ‰§è¡ŒOPARå¾ªç¯
        await self._observe(user_input)
        await self._plan()
        await self._act()
        is_valid = await self._reflect()
        
        # å¤„ç†é‡è¯•
        retries = 0
        max_retries = 2
        
        while not is_valid and retries < max_retries:
            stage_to_retry = self.reflection_result.get("stage_to_retry", "act")
            
            if stage_to_retry == "observe":
                await self._observe(user_input)
                await self._plan()
                await self._act()
            elif stage_to_retry == "plan":
                await self._plan()
                await self._act()
            elif stage_to_retry == "act":
                await self._act()
            
            is_valid = await self._reflect()
            retries += 1
        
        # è¿”å›æœ€ç»ˆç»“æœ
        return {
            "questions": self.action_results,
            "is_valid": is_valid,
            "context": {
                "user_is_new": await self._is_new_user(),
                "observations": self.observation_results,
                "plan": self.plan_results,
                "reflection": self.reflection_result
            }
        }


# ç®€å•æ¼”ç¤ºå‡½æ•°ï¼Œä¾¿äºå¿«é€Ÿæµ‹è¯•
async def run_simple_demo():
    """
    Run a simple demo of the LangChain Question Agent with minimal dependencies.
    This function can be used for basic testing without requiring all project components.
    
    æœ€å°é™ã®ä¾å­˜é–¢ä¿‚ã§LangChain Question Agentã®ç°¡å˜ãªãƒ‡ãƒ¢ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    """
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âš ï¸ è¯·å…ˆè®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        return
    
    from langchain_core.language_models import BaseChatModel
    
    # åˆ›å»ºç®€å•çš„æ¨¡æ‹ŸLLMï¼Œé¿å…å®é™…APIè°ƒç”¨
    class MockChatModel(BaseChatModel):
        def _generate(self, messages, stop=None, run_manager=None, **kwargs):
            return "è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿçš„å›å¤"
        
        def _llm_type(self):
            return "mock_chat_model"
    
    # åˆ›å»ºæœ€å°åŒ–æµ‹è¯•æ‰€éœ€çš„æ¨¡æ‹Ÿå¯¹è±¡
    mock_user = MagicMock()
    mock_user.id = 1
    
    mock_db = AsyncMock()
    mock_db.execute.return_value = AsyncMock()
    
    mock_memory_service = MagicMock()
    mock_memory_service.get_user_memories_list = AsyncMock(return_value=[
        {"content": "ç”¨æˆ·å–œæ¬¢æ—…è¡Œ", "category": "preference"}
    ])
    mock_memory_service.get_user_memory_categories_with_number = AsyncMock(
        return_value={"preference": 1}
    )
    
    mock_mistake_service = MagicMock()
    mock_mistake_service.get_user_mistakes = AsyncMock(return_value=[])
    
    # æ›¿æ¢æœåŠ¡æ–¹æ³•
    original_memory_service = MemoryService
    original_mistake_service = MistakeService
    
    # ä½¿ç”¨è‡ªå®šä¹‰æœåŠ¡æ›¿æ¢åŸå§‹æœåŠ¡
    MemoryService = lambda _: mock_memory_service
    MistakeService = lambda _: mock_mistake_service
    
    try:
        # åˆ›å»ºæ¨¡æ‹Ÿçš„UnitOfWork
        mock_uow = MagicMock()
        mock_uow.db = mock_db
        mock_uow.current_user = mock_user
        
        print("ğŸš€ å¼€å§‹LangChainé—®é¢˜ç”ŸæˆAgentæ¼”ç¤º")
        print("è¿™æ˜¯ä¸€ä¸ªç®€åŒ–ç‰ˆæ¼”ç¤ºï¼Œä»…ç”¨äºæµ‹è¯•åŸºæœ¬åŠŸèƒ½")
        
        # åˆ›å»ºAgentå®ä¾‹
        agent = LangChainQuestionAgent(mock_uow)
        agent.debug = True
        
        # ä½¿ç”¨ç®€å•ç¤ºä¾‹è¿è¡Œ
        result = await agent.run("æˆ‘æƒ³å­¦ä¹ å…³äºæ—…è¡Œçš„æ—¥è¯­")
        
        print("\nâœ… ç”Ÿæˆçš„é—®é¢˜ç»“æ„:")
        print(json.dumps(result, ensure_ascii=False, indent=2))
        
    finally:
        # æ¢å¤åŸå§‹æœåŠ¡ç±»
        MemoryService = original_memory_service
        MistakeService = original_mistake_service


# ä¸ºå•å…ƒæµ‹è¯•å‡†å¤‡çš„æ¼”ç¤ºå‡½æ•°
async def run_test_example(uow: UnitOfWork, user_input: str) -> Dict[str, Any]:
    """
    Run a test example using the provided UnitOfWork.
    This function is designed for unit testing.
    
    æä¾›ã•ã‚ŒãŸUnitOfWorkã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆä¾‹ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
    ã“ã®é–¢æ•°ã¯å˜ä½“ãƒ†ã‚¹ãƒˆç”¨ã«è¨­è¨ˆã•ã‚Œã¦ã„ã¾ã™ã€‚
    """
    agent = LangChainQuestionAgent(uow)
    return await agent.run(user_input)


# å½“ç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶æ—¶æ‰§è¡Œç®€å•æ¼”ç¤º
if __name__ == "__main__":
    asyncio.run(run_simple_demo())